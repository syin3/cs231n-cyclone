{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import modules\n",
    "Run 1st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1.post2\n",
      "Torchvision Version:  0.2.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "import skimage\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train function\n",
    "All learning wrapper calls this training function, because for each caller, we have specified parameters and obejcts to be passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, length, is_inception=False):\n",
    "    since = time.time()\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # best_acc = 0.0\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            # running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        # print(outputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / length[phase]\n",
    "            # epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            # print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_loss_history, train_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: defining and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modified AlexNet by Paper (kddTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### kddTC: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Notice data fed to kddTC should follow the pre-processing steps by the paper\n",
    "Especially, (1) only two channels should be included;\n",
    "(2) middle cropping;\n",
    "(3) rotation?\n",
    "'''\n",
    "class kddAlex(nn.Module):\n",
    "\n",
    "    def __init__(self, num_outputs = 1):\n",
    "        super(kddAlex, self).__init__()\n",
    "        ###\n",
    "        ### Changed 3 to 2 to fit our data dimension sieze\n",
    "        ###\n",
    "        self.features = nn.Sequential(\n",
    "            # nn.Conv2d(2, 64, kernel_size=11, stride=4, padding=2),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(2, 16, kernel_size=4, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Dropout(),\n",
    "            nn.Linear(128 * 3 * 3, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, num_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 128 * 3 * 3)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def kddTC(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = kddAlex(**kwargs)\n",
    "    # if pretrained:\n",
    "    #    state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "    #                                          progress=progress)\n",
    "    #    model.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### kddTCData: Dataset object\n",
    "+ 2 channels;\n",
    "+ middle crop 64\n",
    "+ nan and extreme large treatment to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class kddTCData(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        super(kddTCData, self).__init__()\n",
    "        h5_file = h5py.File(file_path)\n",
    "        self.data = h5_file.get('matrix')\n",
    "        # hard code the Vmax label\n",
    "        self.target = h5_file.get('info/block0_values')[:,2]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # middle crop and permute axis\n",
    "        datMatrix = torch.from_numpy(self.data[index, 68 : (68 + 64), 68 : (68 + 64), [0,3]]).permute(2, 0, 1).float()\n",
    "        # [0,3]\n",
    "        # datMatrix = (datMatrix - datMatrix.mean(axis=0)) / datMatrix.std(axis=0)\n",
    "        labMatrix = torch.from_numpy(self.target)[index].float()\n",
    "        # replace nan with 0\n",
    "        datMatrix = np.nan_to_num(datMatrix)\n",
    "        # replace extremely large values with 0\n",
    "        datMatrix[datMatrix > 1000] = 0\n",
    "        return (datMatrix, labMatrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def length(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### kddTClearn: wrapper function that loads data and calls training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def kddTClearn(model, data_source, batch_size, num_epochs):\n",
    "    dataDic = {\n",
    "        '2017': 'TCIR-ALL_2017.h5',\n",
    "        'c-i-sh': 'TCIR-CPAC_IO_SH.h5',\n",
    "        'a-e-w':'TCIR-ATLN_EPAC_WPAC.h5'\n",
    "    }\n",
    "    transf = {\n",
    "        '2017': {'mean': None, 'std': None},\n",
    "        'c-i-sh': {'mean': None, 'std': None}, \n",
    "        'a-e-w': {'mean': None, 'std': None}\n",
    "    }\n",
    "    data_transform = transforms.Normalize(mean=transf[data_source]['mean'], std=transf[data_source]['std'])\n",
    "    data = kddTCData(dataDic[data_source],\n",
    "                         transform = data_transform)\n",
    "    \n",
    "    NUM_DATA = 500 # data.length()\n",
    "    print(NUM_DATA)\n",
    "    length = {}\n",
    "    length['train'] = int(NUM_DATA * 0.7)\n",
    "    length['val'] = NUM_DATA - int(NUM_DATA * 0.7)\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = DataLoader(data, batch_size=batch_size, \n",
    "                                      sampler=SubsetRandomSampler(range(int(NUM_DATA * 0.7))),\n",
    "                             num_workers=4)\n",
    "    dataloaders['val'] = DataLoader(data, batch_size=batch_size, \n",
    "                                    sampler=SubsetRandomSampler(range(int(NUM_DATA * 0.7), NUM_DATA)),\n",
    "                            num_workers=4)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    # optim.SGD(kdd18.parameters(), lr=0.001, momentum=0.9)\n",
    "    model_optmzer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "\n",
    "    model, val_loss_history, train_loss_history = train_model(model, dataloaders, criterion, \n",
    "                           model_optmzer, num_epochs=num_epochs, length = length)\n",
    "    return model, val_loss_history, train_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kdd18: the model created and to be learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 5227.9162\n",
      "val Loss: 657.3753\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 5091.9267\n",
      "val Loss: 595.9129\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 4952.6401\n",
      "val Loss: 517.6637\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 4750.6253\n",
      "val Loss: 411.2284\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 4479.4202\n",
      "val Loss: 277.9759\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 4098.7953\n",
      "val Loss: 132.6577\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 3605.5051\n",
      "val Loss: 31.7875\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 2997.6089\n",
      "val Loss: 128.9681\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 2398.8438\n",
      "val Loss: 733.8793\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 2116.7122\n",
      "val Loss: 1990.0893\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 2260.5772\n",
      "val Loss: 2493.8110\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 2301.9771\n",
      "val Loss: 1909.2713\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 2154.6664\n",
      "val Loss: 1173.9405\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 2087.1091\n",
      "val Loss: 774.9469\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 2101.6597\n",
      "val Loss: 653.3036\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 2134.5640\n",
      "val Loss: 656.4777\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 2114.4096\n",
      "val Loss: 816.0032\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 2085.6659\n",
      "val Loss: 1055.8312\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 2071.5208\n",
      "val Loss: 1272.0729\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 2085.3277\n",
      "val Loss: 1353.5197\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 2085.9876\n",
      "val Loss: 1265.0861\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 2086.6634\n",
      "val Loss: 1092.6769\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 2078.5929\n",
      "val Loss: 995.4614\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 2084.5437\n",
      "val Loss: 930.0061\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 2080.9291\n",
      "val Loss: 985.2992\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 2073.0009\n",
      "val Loss: 1054.3865\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 2070.8987\n",
      "val Loss: 1114.3988\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 2075.0825\n",
      "val Loss: 1170.4516\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 2074.5773\n",
      "val Loss: 1175.9559\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 2075.9845\n",
      "val Loss: 1120.0711\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 2073.0798\n",
      "val Loss: 1040.2885\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 2073.6987\n",
      "val Loss: 1008.6776\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 2075.6318\n",
      "val Loss: 1005.7450\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 2076.2753\n",
      "val Loss: 1020.3267\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 2075.6758\n",
      "val Loss: 1088.6559\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 2074.8410\n",
      "val Loss: 1077.9123\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 2076.2706\n",
      "val Loss: 1151.7855\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 2072.9757\n",
      "val Loss: 1130.9067\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 2074.3937\n",
      "val Loss: 1107.2109\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 2072.4305\n",
      "val Loss: 1049.8726\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 2072.9419\n",
      "val Loss: 1022.2183\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 2075.4426\n",
      "val Loss: 1043.5033\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 2077.2913\n",
      "val Loss: 1077.3359\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 2073.6574\n",
      "val Loss: 1085.1251\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 2079.0506\n",
      "val Loss: 1048.0777\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 2079.8209\n",
      "val Loss: 1068.0278\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 2086.2985\n",
      "val Loss: 1092.2004\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 2071.3629\n",
      "val Loss: 1080.8835\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 2072.5787\n",
      "val Loss: 1108.0452\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 2077.8235\n",
      "val Loss: 1098.4313\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 2075.8216\n",
      "val Loss: 1153.1407\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 2073.1242\n",
      "val Loss: 1112.3824\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 2075.8965\n",
      "val Loss: 1033.2268\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 2072.4738\n",
      "val Loss: 1065.1639\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 2094.4149\n",
      "val Loss: 1003.6770\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 2082.7832\n",
      "val Loss: 1148.3096\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 2091.3345\n",
      "val Loss: 1187.2576\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 2070.3067\n",
      "val Loss: 1062.2225\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 2083.3080\n",
      "val Loss: 919.5818\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 2078.6492\n",
      "val Loss: 958.5248\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 2071.9771\n",
      "val Loss: 1079.0223\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 2070.4901\n",
      "val Loss: 1177.9190\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 2073.1033\n",
      "val Loss: 1209.4271\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 2081.0081\n",
      "val Loss: 1134.3653\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 2071.3287\n",
      "val Loss: 1093.8046\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 2074.8346\n",
      "val Loss: 1031.7228\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 2070.7505\n",
      "val Loss: 1053.2912\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 2072.0479\n",
      "val Loss: 1068.7810\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 2074.6008\n",
      "val Loss: 1049.1992\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 2069.5008\n",
      "val Loss: 1064.8717\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 2072.7358\n",
      "val Loss: 1123.0537\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 2069.4791\n",
      "val Loss: 1097.2910\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 2070.4434\n",
      "val Loss: 1080.0695\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 2073.8796\n",
      "val Loss: 1004.8891\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 2071.2847\n",
      "val Loss: 1017.4622\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 2066.6134\n",
      "val Loss: 1030.6286\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 2076.9227\n",
      "val Loss: 1080.3763\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 2066.8309\n",
      "val Loss: 1049.7391\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 2066.5371\n",
      "val Loss: 1002.0439\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 2067.0444\n",
      "val Loss: 978.3636\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 2066.5202\n",
      "val Loss: 1035.8299\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 2070.3309\n",
      "val Loss: 1076.1289\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 2064.7193\n",
      "val Loss: 1177.7950\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 2067.8000\n",
      "val Loss: 1132.2392\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 2065.2058\n",
      "val Loss: 1064.1697\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 2066.0556\n",
      "val Loss: 1000.3680\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 2071.0264\n",
      "val Loss: 1049.7689\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 2062.0512\n",
      "val Loss: 1004.0206\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 2071.7735\n",
      "val Loss: 950.3825\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 2067.9857\n",
      "val Loss: 1028.7832\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 2063.6582\n",
      "val Loss: 1187.2876\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 2073.0398\n",
      "val Loss: 1231.1850\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 2065.6663\n",
      "val Loss: 1064.4500\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 2067.3757\n",
      "val Loss: 889.7655\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 2066.8897\n",
      "val Loss: 933.5331\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 2067.5283\n",
      "val Loss: 1057.7182\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 2062.3759\n",
      "val Loss: 1103.2539\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 2067.1825\n",
      "val Loss: 1037.8282\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 2066.6489\n",
      "val Loss: 1058.2614\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 2066.5266\n",
      "val Loss: 988.0896\n",
      "\n",
      "Training complete in 2m 0s\n",
      "Best val Loss: 31.787533\n"
     ]
    }
   ],
   "source": [
    "kdd18 = kddTC(pretrained=False)\n",
    "_, val_loss, train_loss = kddTClearn(kdd18, 'c-i-sh', batch_size = 128, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss, label = 'val')\n",
    "plt.plot(train_loss, label = 'train')\n",
    "plt.title('Losses curve on (500 *0.7) training dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(val_loss, label = 'val')\n",
    "plt.plot(train_loss, label = 'train')\n",
    "plt.title('Losses curve on (150 *0.7) training dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Resnet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# __all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "#            'resnet152']\n",
    "\n",
    "\n",
    "# model_urls = {\n",
    "#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "# }\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        ###\n",
    "        ### change 3 to 2 for our data\n",
    "        ###\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### resnetTCData: Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class resnetTCData(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        super(resnetTCData, self).__init__()\n",
    "        h5_file = h5py.File(file_path)\n",
    "        self.data = h5_file.get('matrix')\n",
    "        # hard code the Vmax label\n",
    "        self.target = h5_file.get('info/block0_values')[:,2]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # middle crop and permute axis\n",
    "        datMatrix = torch.from_numpy(self.data[index, :, :, [0,3]]).permute(2, 0, 1).float()\n",
    "        # [0,3]\n",
    "        # datMatrix = (datMatrix - datMatrix.mean(axis=0)) / datMatrix.std(axis=0)\n",
    "        labMatrix = torch.from_numpy(self.target)[index].float()\n",
    "        # replace nan with 0\n",
    "        datMatrix = np.nan_to_num(datMatrix)\n",
    "        # replace extremely large values with 0\n",
    "        datMatrix[datMatrix > 1000] = 0\n",
    "        return (datMatrix, labMatrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def length(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### resnetTClearn: wrapper that loads and calls training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rensetTClearn(model, data_source, batch_size, num_epochs):\n",
    "    dataDic = {\n",
    "        '2017': 'TCIR-ALL_2017.h5',\n",
    "        'c-i-sh': 'TCIR-CPAC_IO_SH.h5',\n",
    "        'a-e-w':'TCIR-ATLN_EPAC_WPAC.h5'\n",
    "    }\n",
    "    transf = {\n",
    "        '2017': {'mean': None, 'std': None},\n",
    "        'c-i-sh': {'mean': None, 'std': None}, \n",
    "        'a-e-w': {'mean': None, 'std': None}\n",
    "    }\n",
    "    data_transform = transforms.Normalize(mean=transf[data_source]['mean'], std=transf[data_source]['std'])\n",
    "    data = resnetTCData(dataDic[data_source],\n",
    "                         transform = data_transform)\n",
    "    \n",
    "    NUM_DATA = 10 # data.length()\n",
    "    print(NUM_DATA)\n",
    "    length = {}\n",
    "    length['train'] = int(NUM_DATA * 0.7)\n",
    "    length['val'] = NUM_DATA - int(NUM_DATA * 0.7)\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = DataLoader(data, batch_size=batch_size, \n",
    "                                      sampler=SubsetRandomSampler(range(int(NUM_DATA * 0.7))))\n",
    "    dataloaders['val'] = DataLoader(data, batch_size=batch_size, \n",
    "                                    sampler=SubsetRandomSampler(range(int(NUM_DATA * 0.7), NUM_DATA)))\n",
    "    \n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    num_output = 1\n",
    "    model.fc = nn.Linear(num_ftrs, num_output)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    # optim.SGD(kdd18.parameters(), lr=0.001, momentum=0.9)\n",
    "    model_optmzer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "\n",
    "    model, val_loss_history, train_loss_history = train_model(model, dataloaders, criterion, \n",
    "                           model_optmzer, num_epochs=num_epochs, length = length)\n",
    "    return model, val_loss_history, train_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### resnet50TC and resnet34TC: overfitting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 657.2467\n",
      "val Loss: 12498.6523\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 636.6534\n",
      "val Loss: 1912.8895\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 618.5876\n",
      "val Loss: 824.0681\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 599.3378\n",
      "val Loss: 565.8723\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 579.7789\n",
      "val Loss: 483.2373\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 558.6892\n",
      "val Loss: 453.1857\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 536.7385\n",
      "val Loss: 446.2036\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 514.2415\n",
      "val Loss: 455.9376\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 491.1043\n",
      "val Loss: 473.7440\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 467.1476\n",
      "val Loss: 496.0459\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 443.1924\n",
      "val Loss: 519.9662\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 418.4901\n",
      "val Loss: 535.3739\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 394.8045\n",
      "val Loss: 538.0236\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 371.4470\n",
      "val Loss: 536.0168\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 349.3843\n",
      "val Loss: 529.3821\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 328.3347\n",
      "val Loss: 521.0593\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 307.5993\n",
      "val Loss: 509.3301\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 288.2295\n",
      "val Loss: 496.3203\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 269.2618\n",
      "val Loss: 481.7900\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 251.1941\n",
      "val Loss: 466.9328\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 234.0412\n",
      "val Loss: 451.5224\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 217.6762\n",
      "val Loss: 432.2388\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 202.1410\n",
      "val Loss: 414.9937\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 187.4267\n",
      "val Loss: 397.3158\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 173.4525\n",
      "val Loss: 377.1417\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 160.1547\n",
      "val Loss: 356.6902\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 147.5997\n",
      "val Loss: 333.7020\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 135.7683\n",
      "val Loss: 310.2308\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 124.6865\n",
      "val Loss: 285.7948\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 114.2595\n",
      "val Loss: 261.4121\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 104.5079\n",
      "val Loss: 237.8241\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 95.4061\n",
      "val Loss: 214.1626\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 86.9009\n",
      "val Loss: 191.2472\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 78.9892\n",
      "val Loss: 169.4101\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 71.6298\n",
      "val Loss: 148.1729\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 64.8020\n",
      "val Loss: 128.9035\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 58.4785\n",
      "val Loss: 112.0063\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 52.6386\n",
      "val Loss: 96.3747\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 47.2587\n",
      "val Loss: 82.4101\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 42.3189\n",
      "val Loss: 69.8013\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 37.7919\n",
      "val Loss: 58.4715\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 33.6550\n",
      "val Loss: 49.3010\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 29.8870\n",
      "val Loss: 41.6287\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 26.4615\n",
      "val Loss: 35.0659\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 23.3591\n",
      "val Loss: 29.7725\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 20.5558\n",
      "val Loss: 25.3080\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 18.0275\n",
      "val Loss: 21.5039\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 15.7558\n",
      "val Loss: 18.1529\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 13.7220\n",
      "val Loss: 15.3846\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 11.9058\n",
      "val Loss: 13.2025\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 10.2882\n",
      "val Loss: 11.3847\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 8.8520\n",
      "val Loss: 9.8837\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 7.5807\n",
      "val Loss: 8.7297\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 6.4593\n",
      "val Loss: 7.8116\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 5.4744\n",
      "val Loss: 7.0636\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 4.6126\n",
      "val Loss: 6.4535\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 3.8618\n",
      "val Loss: 5.9196\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 3.2110\n",
      "val Loss: 5.4874\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 2.6497\n",
      "val Loss: 5.1577\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 2.1681\n",
      "val Loss: 4.8929\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 1.7576\n",
      "val Loss: 4.6824\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 1.4098\n",
      "val Loss: 4.5284\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 1.1173\n",
      "val Loss: 4.4138\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.8733\n",
      "val Loss: 4.3473\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.6719\n",
      "val Loss: 4.3261\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.5073\n",
      "val Loss: 4.3346\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.3744\n",
      "val Loss: 4.3715\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.2688\n",
      "val Loss: 4.4339\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.1863\n",
      "val Loss: 4.5191\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.1233\n",
      "val Loss: 4.6273\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.0766\n",
      "val Loss: 4.7533\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.0434\n",
      "val Loss: 4.8948\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.0211\n",
      "val Loss: 5.0513\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.0077\n",
      "val Loss: 5.2210\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.0013\n",
      "val Loss: 5.4030\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.0001\n",
      "val Loss: 5.5958\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.0030\n",
      "val Loss: 5.7994\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.0086\n",
      "val Loss: 6.0142\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.0161\n",
      "val Loss: 6.2391\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.0247\n",
      "val Loss: 6.4711\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "val Loss: 6.7094\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.0425\n",
      "val Loss: 6.9524\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.0509\n",
      "val Loss: 7.1990\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.0585\n",
      "val Loss: 7.4479\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.0651\n",
      "val Loss: 7.6983\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.0705\n",
      "val Loss: 7.9504\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.0748\n",
      "val Loss: 8.2030\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.0779\n",
      "val Loss: 8.4553\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.0797\n",
      "val Loss: 8.7052\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.0804\n",
      "val Loss: 8.9536\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.0799\n",
      "val Loss: 9.1971\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.0785\n",
      "val Loss: 9.4336\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.0761\n",
      "val Loss: 9.6643\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.0730\n",
      "val Loss: 9.8902\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.0691\n",
      "val Loss: 10.1105\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.0647\n",
      "val Loss: 10.3265\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.0599\n",
      "val Loss: 10.5356\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.0547\n",
      "val Loss: 10.7339\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.0492\n",
      "val Loss: 10.9262\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.0437\n",
      "val Loss: 11.1097\n",
      "\n",
      "Training complete in 8m 46s\n",
      "Best val Loss: 4.326117\n"
     ]
    }
   ],
   "source": [
    "resnet50TC = resnet50(pretrained=False)\n",
    "_, val_loss, train_loss = rensetTClearn(resnet50TC, 'c-i-sh', batch_size = 128, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label = 'train')\n",
    "plt.title('Losses curve on (10 *0.7) training dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 616.3976\n",
      "val Loss: 48397.8789\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 582.5171\n",
      "val Loss: 10609.5586\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 550.5452\n",
      "val Loss: 3398.2874\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 522.2950\n",
      "val Loss: 1266.1975\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 495.6078\n",
      "val Loss: 508.4494\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 472.3868\n",
      "val Loss: 197.3113\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 451.1628\n",
      "val Loss: 59.9967\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 432.3529\n",
      "val Loss: 8.8070\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 415.2444\n",
      "val Loss: 3.6894\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 399.7489\n",
      "val Loss: 29.8364\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 385.6147\n",
      "val Loss: 75.2636\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 372.4400\n",
      "val Loss: 129.5394\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 360.2335\n",
      "val Loss: 188.1108\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 348.9835\n",
      "val Loss: 242.2749\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 338.6077\n",
      "val Loss: 282.8979\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 328.8919\n",
      "val Loss: 306.6633\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 319.8001\n",
      "val Loss: 310.1518\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 311.3119\n",
      "val Loss: 304.2247\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 303.3498\n",
      "val Loss: 293.6157\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 295.8825\n",
      "val Loss: 281.6188\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 288.8431\n",
      "val Loss: 267.8908\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 282.2005\n",
      "val Loss: 256.7829\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 275.9216\n",
      "val Loss: 246.0307\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 269.9793\n",
      "val Loss: 237.0878\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 264.3236\n",
      "val Loss: 229.2209\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 258.9431\n",
      "val Loss: 222.6474\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 253.8138\n",
      "val Loss: 217.2472\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 248.9223\n",
      "val Loss: 211.8735\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 244.2462\n",
      "val Loss: 207.4555\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 239.7544\n",
      "val Loss: 203.7517\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 235.4565\n",
      "val Loss: 200.6895\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 231.3436\n",
      "val Loss: 197.6679\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 227.3824\n",
      "val Loss: 195.1158\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 223.5482\n",
      "val Loss: 192.8778\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 219.8479\n",
      "val Loss: 191.0217\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 216.2824\n",
      "val Loss: 189.6380\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 212.8259\n",
      "val Loss: 188.6286\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 209.4733\n",
      "val Loss: 187.7189\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 206.2338\n",
      "val Loss: 186.8874\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 203.0918\n",
      "val Loss: 186.1485\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 200.0505\n",
      "val Loss: 185.4550\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 197.1022\n",
      "val Loss: 184.7681\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 194.2279\n",
      "val Loss: 184.0860\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 191.4222\n",
      "val Loss: 183.5043\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 188.6920\n",
      "val Loss: 182.9694\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 186.0284\n",
      "val Loss: 182.4376\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 183.4274\n",
      "val Loss: 181.9040\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 180.8829\n",
      "val Loss: 181.2924\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 178.4016\n",
      "val Loss: 180.5944\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 175.9788\n",
      "val Loss: 179.8656\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 173.6054\n",
      "val Loss: 179.1548\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 171.2768\n",
      "val Loss: 178.4448\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 168.9977\n",
      "val Loss: 177.8361\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 166.7631\n",
      "val Loss: 177.2118\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 164.5734\n",
      "val Loss: 176.6036\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 162.4270\n",
      "val Loss: 175.9893\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 160.3242\n",
      "val Loss: 175.3031\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 158.2612\n",
      "val Loss: 174.5975\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 156.2409\n",
      "val Loss: 173.8311\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 154.2525\n",
      "val Loss: 173.0334\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 152.2985\n",
      "val Loss: 172.1742\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 150.3808\n",
      "val Loss: 171.2788\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 148.4946\n",
      "val Loss: 170.3202\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 146.6406\n",
      "val Loss: 169.3676\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 144.8186\n",
      "val Loss: 168.4507\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 143.0253\n",
      "val Loss: 167.5589\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 141.2613\n",
      "val Loss: 166.5279\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 139.5238\n",
      "val Loss: 165.3106\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 137.8140\n",
      "val Loss: 164.0635\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 136.1319\n",
      "val Loss: 162.8695\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 134.4739\n",
      "val Loss: 161.6821\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 132.8355\n",
      "val Loss: 160.5326\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 131.2244\n",
      "val Loss: 159.3656\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 129.6331\n",
      "val Loss: 158.1640\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 128.0635\n",
      "val Loss: 157.0220\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 126.5187\n",
      "val Loss: 156.0207\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 124.9954\n",
      "val Loss: 154.9832\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 123.4914\n",
      "val Loss: 153.9024\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 122.0077\n",
      "val Loss: 152.7727\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 120.5406\n",
      "val Loss: 151.6331\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 119.0928\n",
      "val Loss: 150.4187\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 117.6662\n",
      "val Loss: 149.1569\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 116.2536\n",
      "val Loss: 147.9933\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 114.8599\n",
      "val Loss: 146.8810\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 113.4819\n",
      "val Loss: 145.7992\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 112.1207\n",
      "val Loss: 144.7544\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 110.7758\n",
      "val Loss: 143.6699\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 109.4459\n",
      "val Loss: 142.4898\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 108.1342\n",
      "val Loss: 141.3478\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 106.8360\n",
      "val Loss: 140.3052\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 105.5516\n",
      "val Loss: 139.3123\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 104.2829\n",
      "val Loss: 138.3067\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 103.0266\n",
      "val Loss: 137.2195\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 101.7866\n",
      "val Loss: 136.0217\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 100.5570\n",
      "val Loss: 134.8244\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 99.3443\n",
      "val Loss: 133.6588\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 98.1419\n",
      "val Loss: 132.5301\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 96.9537\n",
      "val Loss: 131.3305\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 95.7754\n",
      "val Loss: 130.2376\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 94.6119\n",
      "val Loss: 129.0960\n",
      "\n",
      "Training complete in 7m 14s\n",
      "Best val Loss: 3.689364\n"
     ]
    }
   ],
   "source": [
    "resnet34TC = resnet34(pretrained=False)\n",
    "_, val_loss, train_loss = rensetTClearn(resnet34TC, 'c-i-sh', batch_size = 128, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label = 'train')\n",
    "plt.title('Losses curve on (10 *0.7) training dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## classic AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### classicAlex: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class classicAlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(classicAlexNet, self).__init__()\n",
    "        ###\n",
    "        ### Changed 3 to 4 to fit our data dimension sieze\n",
    "        ###\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = classicAlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Playground: before everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load in data from h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = \"TCIR-ALL_2017.h5\"\n",
    "\n",
    "# load \"info\" as pandas dataframe\n",
    "data_info = pd.read_hdf(data_path, key=\"info\", mode='r')\n",
    "\n",
    "# load \"matrix\" as numpy ndarray, this could take longer times\n",
    "with h5py.File(data_path, 'r') as hf:\n",
    "    data_matrix = hf['matrix'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### A sketch of label matrix\n",
    "Vmax is wind speed, MSLP is minimum sea level pressure, R35_4qAVG is radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Several visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(data_info.loc[data_info['ID'] == '201733W']['Vmax'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[0,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[1,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[2,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[10,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Rotate: trial\n",
    "Problematic: except 90, 180, 270, 360 degrees, rotations of all other degrees have incorrect outputs: whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "skimage.transform.rotate(data_matrix[0, :, :, :], 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(data_matrix[0, :, :, 0].flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(skimage.transform.rotate(data_matrix[0, :, :, 0], 1, preserve_range=True).flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "plt.hist(scipy.ndimage.rotate(data_matrix[0, :, :, 0], 1).flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[0, :, :, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(skimage.transform.rotate(data_matrix[0, :, :, 0], 90, preserve_range=True), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.max(data_matrix[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.max(skimage.transform.rotate(data_matrix[0, :, :, 0], 10, preserve_range=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Check how many in matrix is nan\n",
    "Must deal with data outlier as proposed in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.prod(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(data_matrix.shape[0]):\n",
    "    if np.count_nonzero(np.isnan(data_matrix[i, :, :, :])) > 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "print(data_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Show h5df file content and play with data load step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def h5printR(item, leading = ''):\n",
    "    for key in item:\n",
    "        if isinstance(item[key], h5py.Dataset):\n",
    "            print(leading + key + ': ' + str(item[key].shape))\n",
    "        else:\n",
    "            print(leading + key)\n",
    "            h5printR(item[key], leading + '  ')\n",
    "\n",
    "# Print structure of a `.h5` file            \n",
    "def h5print(filename):\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        print(filename)\n",
    "        h5printR(h, '  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_path = 'TCIR-ALL_2017.h5'\n",
    "h5_file = h5py.File(file_path)\n",
    "matrix = h5_file.get('matrix')\n",
    "target = h5_file.get('info') #/block0_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(target['block0_items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h5print('TCIR-ALL_2017.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datMatrix = torch.from_numpy(matrix[:, 68 : 68 + 64, 68 : 68 + 64, [0,3]]).permute(0, 3, 1, 2).float()\n",
    "datMatrix = np.nan_to_num(datMatrix)\n",
    "datMatrix[datMatrix > 1000] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(datMatrix))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
