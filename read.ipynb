{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import modules\n",
    "Run 1st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1.post2\n",
      "Torchvision Version:  0.2.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "import skimage\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define Deep Learning model\n",
    "Run 2nd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "# __all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "#            'resnet152']\n",
    "\n",
    "\n",
    "# model_urls = {\n",
    "#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "# }\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        ###\n",
    "        ### change 3 to 4 for our data\n",
    "        ###\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False) # changed to 4\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### classic AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class classicAlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(classicAlexNet, self).__init__()\n",
    "        ###\n",
    "        ### Changed 3 to 4 to fit our data dimension sieze\n",
    "        ###\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = classicAlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### modified AlexNet by Paper (kddTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Notice data fed to kddTC should follow the pre-processing steps by the paper\n",
    "Especially, (1) only two channels should be included;\n",
    "(2) middle cropping;\n",
    "(3) rotation?\n",
    "'''\n",
    "class kddAlex(nn.Module):\n",
    "\n",
    "    def __init__(self, num_outputs = 1):\n",
    "        super(kddAlex, self).__init__()\n",
    "        ###\n",
    "        ### Changed 3 to 2 to fit our data dimension sieze\n",
    "        ###\n",
    "        self.features = nn.Sequential(\n",
    "            # nn.Conv2d(2, 64, kernel_size=11, stride=4, padding=2),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(2, 16, kernel_size=4, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Dropout(),\n",
    "            nn.Linear(128 * 3 * 3, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, num_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 128 * 3 * 3)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def kddTC(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = kddAlex(**kwargs)\n",
    "    # if pretrained:\n",
    "    #    state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "    #                                          progress=progress)\n",
    "    #    model.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training set mean and variance per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_path = \"TCIR-ALL_2017.h5\"\n",
    "\n",
    "# load \"info\" as pandas dataframe\n",
    "data_info = pd.read_hdf(data_path, key=\"info\", mode='r')\n",
    "\n",
    "# load \"matrix\" as numpy ndarray, this could take longer times\n",
    "with h5py.File(data_path, 'r') as hf:\n",
    "    data_matrix = hf['matrix'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_matrix.reshape(-1, 4).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "skimage.transform.rotate(data_matrix[0, :, :, :], 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(data_matrix[0, :, :, 0].flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(skimage.transform.rotate(data_matrix[0, :, :, 0], 1, preserve_range=True).flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "plt.hist(scipy.ndimage.rotate(data_matrix[0, :, :, 0], 1).flatten(), 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[0, :, :, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(skimage.transform.rotate(data_matrix[0, :, :, 0], 90, preserve_range=True), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.max(data_matrix[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.max(skimage.transform.rotate(data_matrix[0, :, :, 0], 10, preserve_range=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Print shape\n",
    "Must deal with data outlier as proposed in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.prod(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(data_matrix.shape[0]):\n",
    "    if np.count_nonzero(np.isnan(data_matrix[i, :, :, :])) > 0:\n",
    "        count += 1\n",
    "print(count)\n",
    "print(data_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## A sketch of label matrix\n",
    "Vmax is wind speed, MSLP is minimum sea level pressure, R35_4qAVG is radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Several visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(data_info.loc[data_info['ID'] == '201733W']['Vmax'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[0,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[1,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[2,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(data_matrix[10,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a model with Pytorch API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Check h5df file\n",
    "Don't run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def h5printR(item, leading = ''):\n",
    "    for key in item:\n",
    "        if isinstance(item[key], h5py.Dataset):\n",
    "            print(leading + key + ': ' + str(item[key].shape))\n",
    "        else:\n",
    "            print(leading + key)\n",
    "            h5printR(item[key], leading + '  ')\n",
    "\n",
    "# Print structure of a `.h5` file            \n",
    "def h5print(filename):\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        print(filename)\n",
    "        h5printR(h, '  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_path = 'TCIR-ALL_2017.h5'\n",
    "h5_file = h5py.File(file_path)\n",
    "matrix = h5_file.get('matrix')\n",
    "target = h5_file.get('info') #/block0_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(target['block0_items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h5print('TCIR-ALL_2017.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datMatrix = torch.from_numpy(matrix[:, 68 : 68 + 64, 68 : 68 + 64, [0,3]]).permute(0, 3, 1, 2).float()\n",
    "datMatrix = np.nan_to_num(datMatrix)\n",
    "datMatrix[datMatrix > 1000] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(np.isnan(datMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue: data load, model train\n",
    "+ **Run 3rd**.<br>\n",
    "+ Dimension does not match. Pytorch defaults to $N\\times C\\times H\\times W$, while our data comes in $N\\times H\\times W\\times C\\$. Use **permute()** to swap axis. <br>\n",
    "+ Next, we have four channels while resnet only accepts 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kddTCData(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        super(kddTCData, self).__init__()\n",
    "        h5_file = h5py.File(file_path)\n",
    "        self.data = h5_file.get('matrix')\n",
    "        # hard code the Vmax label\n",
    "        self.target = h5_file.get('info/block0_values')[:,2]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # middle crop and permute axis\n",
    "        datMatrix = torch.from_numpy(self.data[index, 68 : (68 + 64), 68 : (68 + 64), [0,3]]).permute(2, 0, 1).float()\n",
    "        # datMatrix = (datMatrix - datMatrix.mean(axis=0)) / datMatrix.std(axis=0)\n",
    "        labMatrix = torch.from_numpy(self.target)[index].float()\n",
    "        # replace nan with 0\n",
    "        datMatrix = np.nan_to_num(datMatrix)\n",
    "        # replace extremely large values with 0\n",
    "        datMatrix[datMatrix > 1000] = 0\n",
    "        return (datMatrix, labMatrix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def length(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, is_inception=False):\n",
    "    since = time.time()\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # best_acc = 0.0\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            # running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        # print(outputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            print(phase, len(dataloaders[phase].dataset))\n",
    "            # epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            # print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_loss_history, train_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(model, data_source, batch_size, num_epochs):\n",
    "    dataDic = {\n",
    "        '2017': 'TCIR-ALL_2017.h5',\n",
    "        'c-i-sh': 'TCIR-CPAC_IO_SH.h5',\n",
    "        'a-e-w':'TCIR-ATLN_EPAC_WPAC.h5'\n",
    "    }\n",
    "    transf = {\n",
    "        '2017': {'mean': None, 'std': None},\n",
    "        'c-i-sh': {'mean': None, 'std': None}, \n",
    "        'a-e-w': {'mean': None, 'std': None}\n",
    "    }\n",
    "    data_transform = transforms.Normalize(mean=transf[data_source]['mean'], std=transf[data_source]['std'])\n",
    "    data = kddTCData(dataDic[data_source],\n",
    "                         transform = data_transform)\n",
    "    \n",
    "    NUM_DATA = data.length()\n",
    "    print(NUM_DATA)\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = DataLoader(data, batch_size=batch_size, \n",
    "                              sampler=sampler.SubsetRandomSampler(range(int(NUM_DATA * 0.7))),\n",
    "                             num_workers=4)\n",
    "    dataloaders['val'] = DataLoader(data, batch_size=batch_size, \n",
    "                            sampler=sampler.SubsetRandomSampler(range(int(NUM_DATA * 0.7), NUM_DATA)),\n",
    "                            num_workers=4)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    # optim.SGD(kdd18.parameters(), lr=0.001, momentum=0.9)\n",
    "    model_optmzer = optim.Adam(model.parameters(), lr=0.00002)\n",
    "\n",
    "    model, val_loss_history, train_loss_history = train_model(model, dataloaders, criterion, \n",
    "                           model_optmzer, num_epochs=num_epochs)\n",
    "    return model, val_loss_history, train_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23118\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 797.9019\n",
      "val Loss: 235.9215\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 539.3638\n",
      "val Loss: 238.1276\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 538.2669\n",
      "val Loss: 235.1589\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 537.9621\n",
      "val Loss: 235.1429\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 537.0011\n",
      "val Loss: 235.1195\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 534.5510\n",
      "val Loss: 235.8191\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 534.2736\n",
      "val Loss: 239.8773\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 533.5470\n",
      "val Loss: 237.7499\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 532.5983\n",
      "val Loss: 245.3387\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 531.8875\n",
      "val Loss: 236.0955\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 532.6863\n",
      "val Loss: 234.4076\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 532.0000\n",
      "val Loss: 233.6511\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 530.7246\n",
      "val Loss: 237.6955\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 529.5785\n",
      "val Loss: 238.4636\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 528.5593\n",
      "val Loss: 237.4007\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 528.6522\n",
      "val Loss: 232.3337\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 528.7236\n",
      "val Loss: 234.6179\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 529.3879\n",
      "val Loss: 237.4497\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 527.8484\n",
      "val Loss: 232.4724\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 527.3676\n",
      "val Loss: 232.3483\n",
      "\n",
      "Training complete in 9m 50s\n",
      "Best val Loss: 232.333694\n"
     ]
    }
   ],
   "source": [
    "kdd18 = kddTC(pretrained=False)\n",
    "_, val_loss, train_loss = learn(kdd18, 'c-i-sh', batch_size = 64, num_epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss, label = 'val')\n",
    "plt.plot(train_loss, label = 'train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resnet = resnet34(pretrained=False)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "num_output = 1\n",
    "resnet.fc = nn.Linear(num_ftrs, num_output)\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "resnet_optmzer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "resnet = train_model(resnet, dataloaders, criterion, \n",
    "                       resnet_optmzer, num_epochs=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
